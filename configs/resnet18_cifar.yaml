# lightning.pytorch==2.1.3
seed_everything: true
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  logger:  # Set to 'wandb' or 'tensorboard' to enable logging
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      save_dir: '.'
      project: resnet18_cifar
  callbacks:
  - class_path: lightning.pytorch.callbacks.ModelSummary
    init_args:
      max_depth: 2
  - class_path: lightning.pytorch.callbacks.ModelCheckpoint
    init_args:
      dirpath: null
      filename: null
      monitor: val_loss
      verbose: false
      save_last: null
      save_top_k: 3
      mode: min
      auto_insert_metric_name: true
      enable_version_counter: true
  - class_path: lightning.pytorch.callbacks.EarlyStopping
    init_args:
      monitor: val_loss
      min_delta: 1.0e-6
      patience: 15
      verbose: false
      mode: min
  fast_dev_run: false  # Set to true for debugging
  max_epochs: 60
  enable_checkpointing: null
  enable_progress_bar: null
  enable_model_summary: true
ckpt_path: null
model:
  class_path: awesomeness.models.ResNet18LightningModule
  init_args:
    num_outputs: 10
    fc_hidden: [128, 64]
    weights: DEFAULT
    criterion:
      class_path: torch.nn.CrossEntropyLoss
      init_args:
        weight: null
        reduction: mean
data:
  class_path: awesomeness.data.CIFAR10LightningDataModule
  init_args:
    root: ./data
    batch_size: 512
    train_fraction: 0.8
    num_workers: null
    pin_memory: false
optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 0.003
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
    weight_decay: 0.01
    amsgrad: false
    maximize: false